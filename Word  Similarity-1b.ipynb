{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOC0oC4u1z/vSJPn7QlQ8yd"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"WZdfUPAKWqnX"},"outputs":[],"source":["from gensim.models import KeyedVectors\n","from scipy.stats import spearmanr\n","\n","# Load pretrained embeddings, e.g., GloVe\n","model = KeyedVectors.load_word2vec_format(r\"C:\\Users\\hp\\OneDrive\\Desktop\\My Desktop\\Precog\\Recruitment Tasks\\SimLex-999\\SimLex-999.txt\", binary=False, no_header=True)\n","\n","def evaluate_word_similarity(word_pairs, human_scores):\n","    predicted_scores = []\n","    for w1, w2 in word_pairs:\n","        if w1 in model.key_to_index and w2 in model.key_to_index:\n","            similarity = model.similarity(w1, w2)\n","        else:\n","            similarity = 0  # Handle OOV words\n","        predicted_scores.append(similarity)\n","\n","    spearman_corr, _ = spearmanr(human_scores, predicted_scores)\n","    return spearman_corr\n","\n","# Example usage\n","word_pairs = [('word1', 'word2'), ('word3', 'word4')]  # Replace with actual word pairs\n","human_scores = [0.8, 0.6]  # Replace with actual human scores\n","print(\"Spearman Correlation:\", evaluate_word_similarity(word_pairs, human_scores))\n"]},{"cell_type":"code","source":["from transformers import BertTokenizer, BertModel\n","import torch\n","\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","model = BertModel.from_pretrained('bert-base-uncased')\n","\n","def get_contextual_embedding(word, sentence):\n","    inputs = tokenizer(sentence, return_tensors='pt')\n","    outputs = model(**inputs)\n","    last_hidden_states = outputs.last_hidden_state\n","    word_index = sentence.split().index(word)\n","    return last_hidden_states[0][word_index].detach().numpy()\n","\n","# Example usage\n","sentence = \"The bank is on the river\"\n","word = \"bank\"\n","embedding = get_contextual_embedding(word, sentence)\n","print(\"Contextual Embedding:\", embedding)"],"metadata":{"id":"IQORK027WrWg"},"execution_count":null,"outputs":[]}]}
